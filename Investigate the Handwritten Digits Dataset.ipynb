{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We will investigate the handwritten digits dataset.\n",
    "* Sample images:\n",
    "<img src=\"Mnist.png\">\n",
    "\n",
    "* Please apply the folowing eight methods to classify the handwritten digits dataset.\n",
    "* Split the dataset into training sets and test sets\n",
    "* Fit the training data sets to the following eight algorithms\n",
    "* Print the classification report on the test data sets\n",
    "\n",
    "<h4>Method 1: KNN</h4>\n",
    "<h4>Method 2: Linear SVM</h4>\n",
    "<h4>Method 3: Gaussian Kernel SVM</h4>\n",
    "<h4>Method 4: Naive Bayes</h4>\n",
    "<h4>Method 5: Decision Tree</h4>   \n",
    "<h4>Method 6: Random Forest</h4> \n",
    "<h4>Method 7: Voting Classifier</h4> \n",
    "<h4>Method 8: Bagging</h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "from sklearn.datasets import load_digits\n",
    "import numpy as np\n",
    "digits = load_digits(n_class=10,return_X_y=False)\n",
    "# The above parameters n_class will return the number of classes and the return_X_y returns a \n",
    "# bunch object when set to False\n",
    "# (data and target) object if set to true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Looking into the digits dataset\n",
      "===============================\n",
      "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
      "       ...,\n",
      "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
      "       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), 'target': array([0, 1, 2, ..., 8, 9, 8]), 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
      "        [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
      "        [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
      "        [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
      "        [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
      "        [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
      "        [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
      "        [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
      "        [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
      "        [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
      "        [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
      "        [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
      "        [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
      "        [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]), 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttp://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\"}\n"
     ]
    }
   ],
   "source": [
    "# Data of the dataset\n",
    "print(\"===============================\")\n",
    "print(\"Looking into the digits dataset\")\n",
    "print(\"===============================\")\n",
    "print(digits)\n",
    "# It's an dictionary like object\n",
    "# The attributes data \n",
    "# Dictionary-like object, the interesting attributes are: ‘data’, the data to learn, ‘images’, the images \n",
    "# corresponding to each sample, ‘target’, the classification labels for each sample, ‘target_names’, the meaning of the labels, and ‘DESCR’, the full description of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================\n",
      "Digits data shape\n",
      "=================\n",
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "# Shape of the digits data\n",
    "print(\"=================\")\n",
    "print(\"Digits data shape\")\n",
    "print(\"=================\")\n",
    "print(digits.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      "Digits images shape\n",
      "===================\n",
      "(1797, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "# Shape of the image dataset\n",
    "print(\"===================\")\n",
    "print(\"Digits images shape\")\n",
    "print(\"===================\")\n",
    "print(digits.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape the images shape\n",
    "#print(digits.images.shape)\n",
    "#temp_image_shape=digits.images.shape[1]*digits.images.shape[2]\n",
    "#image_reshape=digits.images.reshape(digits.images.shape[0],temp_image_shape)\n",
    "image_reshape=digits.images.reshape([1797,8*8])\n",
    "image_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      "Digits target shape\n",
      "===================\n",
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "# Shape of the digits target\n",
    "print(\"===================\")\n",
    "print(\"Digits target shape\")\n",
    "print(\"===================\")\n",
    "print(digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "Digits Target_names shape\n",
      "=========================\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "# Shape of the digits target_name\n",
    "print(\"=========================\")\n",
    "print(\"Digits Target_names shape\")\n",
    "print(\"=========================\")\n",
    "print(digits.target_names.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "Data in the digits dataset\n",
      "==========================\n",
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Print the data in the digit dataset\n",
    "print(\"==========================\")\n",
    "print(\"Data in the digits dataset\")\n",
    "print(\"==========================\")\n",
    "print(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      "Target Data\n",
      "===========\n",
      "[0 1 2 ... 8 9 8]\n"
     ]
    }
   ],
   "source": [
    "# Print the target data\n",
    "print(\"===========\")\n",
    "print(\"Target Data\")\n",
    "print(\"===========\")\n",
    "print(digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "Target_names in the digits dataset\n",
      "==================================\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Print the target_names in the digits dataset\n",
    "print(\"==================================\")\n",
    "print(\"Target_names in the digits dataset\")\n",
    "print(\"==================================\")\n",
    "print(digits.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "image_reshape data\n",
      "==================\n",
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Print the image_reshape in the digits dataset which is the feature after image reshape\n",
    "print(\"==================\")\n",
    "print(\"image_reshape data\")\n",
    "print(\"==================\")\n",
    "print(image_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "images data in the digits dataset\n",
      "=================================\n",
      "[[[ 0.  0.  5. ...  1.  0.  0.]\n",
      "  [ 0.  0. 13. ... 15.  5.  0.]\n",
      "  [ 0.  3. 15. ... 11.  8.  0.]\n",
      "  ...\n",
      "  [ 0.  4. 11. ... 12.  7.  0.]\n",
      "  [ 0.  2. 14. ... 12.  0.  0.]\n",
      "  [ 0.  0.  6. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  5.  0.  0.]\n",
      "  [ 0.  0.  0. ...  9.  0.  0.]\n",
      "  [ 0.  0.  3. ...  6.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  0.  1. ...  6.  0.  0.]\n",
      "  [ 0.  0.  1. ...  6.  0.  0.]\n",
      "  [ 0.  0.  0. ... 10.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ... 12.  0.  0.]\n",
      "  [ 0.  0.  3. ... 14.  0.  0.]\n",
      "  [ 0.  0.  8. ... 16.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  9. 16. ...  0.  0.  0.]\n",
      "  [ 0.  3. 13. ... 11.  5.  0.]\n",
      "  [ 0.  0.  0. ... 16.  9.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.  0.  1. ...  1.  0.  0.]\n",
      "  [ 0.  0. 13. ...  2.  1.  0.]\n",
      "  [ 0.  0. 16. ... 16.  5.  0.]\n",
      "  ...\n",
      "  [ 0.  0. 16. ... 15.  0.  0.]\n",
      "  [ 0.  0. 15. ... 16.  0.  0.]\n",
      "  [ 0.  0.  2. ...  6.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  2. ...  0.  0.  0.]\n",
      "  [ 0.  0. 14. ... 15.  1.  0.]\n",
      "  [ 0.  4. 16. ... 16.  7.  0.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ... 16.  2.  0.]\n",
      "  [ 0.  0.  4. ... 16.  2.  0.]\n",
      "  [ 0.  0.  5. ... 12.  0.  0.]]\n",
      "\n",
      " [[ 0.  0. 10. ...  1.  0.  0.]\n",
      "  [ 0.  2. 16. ...  1.  0.  0.]\n",
      "  [ 0.  0. 15. ... 15.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  4. 16. ... 16.  6.  0.]\n",
      "  [ 0.  8. 16. ... 16.  8.  0.]\n",
      "  [ 0.  1.  8. ... 12.  1.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "# Print the images in the digits dataset\n",
    "print(\"=================================\")\n",
    "print(\"images data in the digits dataset\")\n",
    "print(\"=================================\")\n",
    "print(digits.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Data of the desc\n",
      "================\n",
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the desc feaure. The DESCR has no shape when trying to issue the print(digits.DESCR.shape)\n",
    "# it is throwing an error that 'str' object has no attribute 'shape'. So printing the data in DESCR\n",
    "print(\"================\")\n",
    "print(\"Data of the desc\")\n",
    "print(\"================\")\n",
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.gray() \n",
    "plt.matshow(digits.images[5]) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  digits.data\n",
    "y =  digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 1. Split the dataset into training data and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the default training anf test size 70 and 30. You can add the parameter test_size=0.3 in the train_test_split\n",
    "# By default it'll divide the dataset in the ratio 70 and 30\n",
    "from sklearn.model_selection import train_test_split \n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Algorithm Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "Score of the training sets\n",
      "==========================\n",
      "0.9925760950259837\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "# Fit knn to the training sets\n",
    "knn.fit(train_X, train_y)\n",
    "# Print the score of knn on the train and test sets\n",
    "print(\"==========================\")\n",
    "print(\"Score of the training sets\")\n",
    "print(\"==========================\")\n",
    "print(knn.score(train_X, train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============\n",
      "y prediction\n",
      "============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 1, 0, 1, 7, 8, 7, 7, 6, 6, 6, 9, 5, 5, 5, 7, 0, 1, 8, 7, 8, 1,\n",
       "       1, 2, 1, 7, 4, 4, 7, 3, 1, 5, 2, 2, 8, 2, 2, 4, 5, 9, 0, 2, 3, 5,\n",
       "       4, 7, 7, 0, 2, 2, 0, 2, 5, 3, 3, 5, 7, 0, 1, 6, 7, 4, 2, 8, 0, 1,\n",
       "       2, 1, 2, 1, 7, 7, 7, 2, 2, 2, 6, 4, 9, 1, 5, 7, 4, 6, 5, 5, 8, 1,\n",
       "       8, 6, 3, 0, 9, 4, 6, 9, 3, 2, 3, 9, 2, 7, 1, 5, 5, 6, 1, 8, 2, 8,\n",
       "       6, 9, 0, 9, 2, 8, 2, 1, 9, 3, 5, 9, 9, 8, 1, 9, 5, 1, 5, 4, 0, 3,\n",
       "       5, 7, 1, 3, 4, 2, 3, 6, 0, 6, 3, 6, 1, 4, 6, 7, 8, 3, 1, 5, 8, 7,\n",
       "       0, 8, 0, 0, 8, 5, 1, 5, 5, 8, 0, 5, 2, 3, 0, 2, 2, 2, 7, 4, 0, 9,\n",
       "       3, 3, 9, 6, 1, 1, 0, 0, 6, 2, 5, 8, 5, 3, 8, 3, 1, 3, 7, 6, 4, 5,\n",
       "       5, 6, 3, 0, 5, 8, 5, 1, 0, 4, 3, 7, 1, 6, 2, 0, 9, 1, 7, 6, 8, 6,\n",
       "       3, 0, 0, 5, 6, 5, 3, 5, 0, 8, 3, 3, 1, 7, 9, 7, 9, 8, 2, 3, 4, 1,\n",
       "       1, 2, 8, 5, 4, 1, 3, 5, 1, 4, 5, 7, 4, 6, 0, 3, 9, 7, 0, 8, 4, 8,\n",
       "       9, 9, 9, 9, 6, 1, 0, 5, 5, 4, 0, 1, 3, 3, 6, 2, 0, 9, 1, 3, 7, 3,\n",
       "       7, 0, 2, 6, 6, 6, 2, 7, 0, 7, 8, 8, 7, 4, 5, 7, 8, 9, 6, 7, 6, 6,\n",
       "       9, 4, 8, 2, 9, 4, 5, 4, 6, 9, 2, 8, 9, 9, 8, 4, 1, 2, 5, 2, 6, 7,\n",
       "       6, 8, 6, 0, 6, 4, 3, 4, 7, 3, 3, 1, 4, 9, 0, 7, 6, 1, 4, 9, 1, 0,\n",
       "       9, 1, 4, 9, 6, 3, 4, 6, 2, 3, 7, 3, 4, 0, 9, 2, 0, 7, 8, 9, 5, 7,\n",
       "       0, 8, 3, 1, 4, 1, 7, 6, 9, 5, 4, 5, 8, 5, 6, 3, 8, 0, 9, 4, 0, 8,\n",
       "       3, 4, 3, 2, 2, 3, 1, 7, 5, 6, 4, 5, 4, 3, 9, 2, 7, 6, 9, 2, 9, 7,\n",
       "       1, 6, 2, 7, 6, 0, 0, 5, 3, 4, 4, 4, 9, 1, 4, 5, 7, 7, 0, 1, 1, 8,\n",
       "       0, 2, 9, 0, 4, 4, 1, 8, 4, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the test set results\n",
    "y_pred=knn.predict(test_X)\n",
    "print(\"============\")\n",
    "print(\"y prediction\")\n",
    "print(\"============\")\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Confusion Matirx\n",
      "================\n",
      "[[45  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 46  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 44  0  0  0  2  0  0]\n",
      " [ 0  0  0  0 45  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 46  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 45  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 45  0  0]\n",
      " [ 0  4  0  0  0  0  0  0 39  0]\n",
      " [ 0  0  0  2  0  1  0  0  0 42]]\n"
     ]
    }
   ],
   "source": [
    "# For calculating the performance we use the confision matrix\n",
    "confusion_matrix_knn_performance= confusion_matrix(test_y, y_pred)\n",
    "print(\"================\")\n",
    "print(\"Confusion Matirx\")\n",
    "print(\"================\")\n",
    "print(confusion_matrix_knn_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Report\n",
      "======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        45\n",
      "           1       0.92      1.00      0.96        46\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       0.96      0.96      0.96        46\n",
      "           4       1.00      1.00      1.00        45\n",
      "           5       0.98      1.00      0.99        46\n",
      "           6       1.00      1.00      1.00        45\n",
      "           7       0.96      1.00      0.98        45\n",
      "           8       1.00      0.91      0.95        43\n",
      "           9       1.00      0.93      0.97        45\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       450\n",
      "   macro avg       0.98      0.98      0.98       450\n",
      "weighted avg       0.98      0.98      0.98       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"======\")\n",
    "print(\"Report\")\n",
    "print(\"======\")\n",
    "report = classification_report(test_y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "Accuracy for KNN Model\n",
      "======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Caluculate the Accuracy, Weighted Precision and Weighted Recall\n",
    "# Acuuracy=TP+TN/P+N [0][0]+[1][1]/P+N\n",
    "# Given by the formula\n",
    "# Accuracy=∑iAii/∑i∑jAij\n",
    "#Accuracy=(45+46+44+45+45+44+45+45+42+42)/(45+46+44+45+1+45+44+2+45+45+1+42+1+1+42)\n",
    "#Accuracy for KNN Model\n",
    "print(\"======================\")\n",
    "print(\"Accuracy for KNN Model\")\n",
    "print(\"======================\")\n",
    "#Accuracy\n",
    "# Calculating accuracy using the sklearn_matrix\n",
    "accuracy_score(test_y, y_pred,normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "Weighted_Precision for KNN Model\n",
      "================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9809475177304964"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"================================\")\n",
    "print(\"Weighted_Precision for KNN Model\")\n",
    "print(\"================================\")\n",
    "precision_score(test_y,y_pred,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "Weighted_Recall for KNN Model\n",
      "================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"================================\")\n",
    "print(\"Weighted_Recall for KNN Model\")\n",
    "print(\"================================\")\n",
    "recall_score(test_y,y_pred,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy Manually\n",
    "Accuracy=(confusion_matrix_knn_performance[0][0]+confusion_matrix_knn_performance[1][1]\n",
    "+confusion_matrix_knn_performance[2][2]+confusion_matrix_knn_performance[3][3]\n",
    "+confusion_matrix_knn_performance[4][4]+confusion_matrix_knn_performance[5][5]\n",
    "+confusion_matrix_knn_performance[6][6]+confusion_matrix_knn_performance[7][7]\n",
    "+confusion_matrix_knn_performance[8][8]+confusion_matrix_knn_performance[9][9])/450\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted Precision\n",
    "Precision_0=confusion_matrix_knn_performance[0][0]/(confusion_matrix_knn_performance[0][0]+\n",
    "confusion_matrix_knn_performance[1][0]+confusion_matrix_knn_performance[2][0]+\n",
    "confusion_matrix_knn_performance[3][0]+confusion_matrix_knn_performance[4][0]+\n",
    "confusion_matrix_knn_performance[5][0]+confusion_matrix_knn_performance[6][0]+\n",
    "confusion_matrix_knn_performance[7][0]+confusion_matrix_knn_performance[8][0]+\n",
    "confusion_matrix_knn_performance[9][0])\n",
    "Precision_1=confusion_matrix_knn_performance[1][1]/(confusion_matrix_knn_performance[0][1]+\n",
    "confusion_matrix_knn_performance[1][1]+confusion_matrix_knn_performance[2][1]+\n",
    "confusion_matrix_knn_performance[3][1]+confusion_matrix_knn_performance[4][1]+\n",
    "confusion_matrix_knn_performance[5][1]+confusion_matrix_knn_performance[6][1]+\n",
    "confusion_matrix_knn_performance[7][1]+confusion_matrix_knn_performance[8][1]+\n",
    "confusion_matrix_knn_performance[9][1])\n",
    "Precision_2=confusion_matrix_knn_performance[2][2]/(confusion_matrix_knn_performance[0][2]+\n",
    "confusion_matrix_knn_performance[1][2]+confusion_matrix_knn_performance[2][2]+\n",
    "confusion_matrix_knn_performance[3][2]+confusion_matrix_knn_performance[4][2]+\n",
    "confusion_matrix_knn_performance[5][2]+confusion_matrix_knn_performance[6][2]+\n",
    "confusion_matrix_knn_performance[7][2]+confusion_matrix_knn_performance[8][2]+\n",
    "confusion_matrix_knn_performance[9][2])\n",
    "Precision_3=confusion_matrix_knn_performance[3][3]/(confusion_matrix_knn_performance[0][3]+\n",
    "confusion_matrix_knn_performance[1][3]+confusion_matrix_knn_performance[2][3]+\n",
    "confusion_matrix_knn_performance[3][3]+confusion_matrix_knn_performance[4][3]+\n",
    "confusion_matrix_knn_performance[5][3]+confusion_matrix_knn_performance[6][3]+\n",
    "confusion_matrix_knn_performance[7][3]+confusion_matrix_knn_performance[8][3]+\n",
    "confusion_matrix_knn_performance[9][3])\n",
    "Precision_4=confusion_matrix_knn_performance[4][4]/(confusion_matrix_knn_performance[0][4]+\n",
    "confusion_matrix_knn_performance[1][4]+confusion_matrix_knn_performance[2][4]+\n",
    "confusion_matrix_knn_performance[3][4]+confusion_matrix_knn_performance[4][4]+\n",
    "confusion_matrix_knn_performance[5][4]+confusion_matrix_knn_performance[6][4]+\n",
    "confusion_matrix_knn_performance[7][4]+confusion_matrix_knn_performance[8][4]+\n",
    "confusion_matrix_knn_performance[9][4])\n",
    "Precision_5=confusion_matrix_knn_performance[5][5]/(confusion_matrix_knn_performance[0][5]+\n",
    "confusion_matrix_knn_performance[1][5]+confusion_matrix_knn_performance[2][5]+\n",
    "confusion_matrix_knn_performance[3][5]+confusion_matrix_knn_performance[4][5]+\n",
    "confusion_matrix_knn_performance[5][5]+confusion_matrix_knn_performance[6][5]+\n",
    "confusion_matrix_knn_performance[7][5]+confusion_matrix_knn_performance[8][5]+\n",
    "confusion_matrix_knn_performance[9][5])\n",
    "Precision_6=confusion_matrix_knn_performance[6][6]/(confusion_matrix_knn_performance[0][6]+\n",
    "confusion_matrix_knn_performance[1][6]+confusion_matrix_knn_performance[2][6]+\n",
    "confusion_matrix_knn_performance[3][6]+confusion_matrix_knn_performance[4][6]+\n",
    "confusion_matrix_knn_performance[5][6]+confusion_matrix_knn_performance[6][6]+\n",
    "confusion_matrix_knn_performance[7][6]+confusion_matrix_knn_performance[8][6]+\n",
    "confusion_matrix_knn_performance[9][6])\n",
    "Precision_7=confusion_matrix_knn_performance[7][7]/(confusion_matrix_knn_performance[0][7]+\n",
    "confusion_matrix_knn_performance[1][7]+confusion_matrix_knn_performance[2][7]+\n",
    "confusion_matrix_knn_performance[3][7]+confusion_matrix_knn_performance[4][7]+\n",
    "confusion_matrix_knn_performance[5][7]+confusion_matrix_knn_performance[6][7]+\n",
    "confusion_matrix_knn_performance[7][7]+confusion_matrix_knn_performance[8][7]+\n",
    "confusion_matrix_knn_performance[9][7])\n",
    "Precision_8=confusion_matrix_knn_performance[8][8]/(confusion_matrix_knn_performance[0][8]+\n",
    "confusion_matrix_knn_performance[1][8]+confusion_matrix_knn_performance[2][8]+\n",
    "confusion_matrix_knn_performance[3][8]+confusion_matrix_knn_performance[4][8]+\n",
    "confusion_matrix_knn_performance[5][8]+confusion_matrix_knn_performance[6][8]+\n",
    "confusion_matrix_knn_performance[7][8]+confusion_matrix_knn_performance[8][8]+\n",
    "confusion_matrix_knn_performance[9][8])\n",
    "Precision_9=confusion_matrix_knn_performance[9][9]/(confusion_matrix_knn_performance[0][9]+\n",
    "confusion_matrix_knn_performance[1][9]+confusion_matrix_knn_performance[2][9]+\n",
    "confusion_matrix_knn_performance[3][9]+confusion_matrix_knn_performance[4][9]+\n",
    "confusion_matrix_knn_performance[5][9]+confusion_matrix_knn_performance[6][9]+\n",
    "confusion_matrix_knn_performance[7][9]+confusion_matrix_knn_performance[8][9]+\n",
    "confusion_matrix_knn_performance[9][9])\n",
    "Weighted_Precision=(Precision_0+Precision_1+Precision_2+Precision_3+Precision_4+Precision_5+Precision_6+Precision_7\n",
    "+Precision_8+Precision_9)/10\n",
    "Weighted_Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2. Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Classifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_svm = SVC(kernel='linear')\n",
    "# Fit the model with training data\n",
    "linear_svm.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============\n",
      "y prediction\n",
      "============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 1, 0, 1, 7, 8, 7, 7, 6, 6, 6, 9, 5, 5, 5, 8, 0, 1, 8, 7, 8, 1,\n",
       "       1, 2, 1, 7, 4, 4, 7, 3, 1, 5, 2, 2, 8, 2, 2, 4, 5, 9, 0, 2, 3, 5,\n",
       "       4, 9, 9, 0, 2, 2, 0, 2, 5, 3, 3, 5, 7, 0, 1, 6, 7, 4, 2, 8, 0, 1,\n",
       "       2, 1, 2, 1, 7, 7, 7, 2, 2, 2, 6, 4, 9, 1, 5, 7, 4, 6, 5, 5, 8, 1,\n",
       "       8, 6, 5, 0, 9, 4, 6, 9, 3, 2, 3, 9, 2, 7, 1, 5, 5, 6, 1, 2, 2, 8,\n",
       "       6, 9, 0, 9, 2, 8, 2, 1, 9, 3, 5, 9, 9, 8, 1, 9, 1, 1, 5, 4, 0, 3,\n",
       "       5, 7, 1, 3, 4, 2, 3, 6, 0, 6, 3, 6, 1, 4, 6, 7, 8, 3, 8, 5, 8, 7,\n",
       "       0, 8, 0, 0, 8, 5, 1, 5, 5, 8, 0, 5, 2, 3, 0, 2, 2, 2, 7, 4, 0, 9,\n",
       "       3, 3, 9, 6, 1, 1, 0, 0, 6, 2, 5, 8, 5, 3, 8, 3, 1, 8, 7, 6, 4, 5,\n",
       "       5, 6, 3, 0, 5, 8, 5, 1, 0, 4, 3, 7, 1, 6, 2, 0, 9, 1, 7, 6, 8, 6,\n",
       "       3, 0, 0, 5, 6, 5, 3, 5, 0, 8, 3, 3, 1, 7, 9, 7, 9, 8, 2, 3, 4, 1,\n",
       "       1, 2, 8, 5, 4, 1, 3, 5, 1, 4, 5, 7, 4, 6, 0, 3, 9, 7, 0, 8, 4, 8,\n",
       "       9, 9, 9, 9, 6, 1, 0, 5, 5, 4, 0, 1, 3, 3, 6, 2, 0, 9, 1, 3, 7, 3,\n",
       "       7, 0, 2, 6, 6, 6, 2, 7, 0, 7, 8, 8, 7, 4, 5, 7, 8, 9, 6, 7, 6, 6,\n",
       "       9, 4, 8, 2, 5, 4, 5, 4, 6, 9, 1, 8, 9, 9, 8, 4, 1, 2, 5, 2, 6, 7,\n",
       "       6, 8, 6, 0, 6, 4, 3, 4, 7, 3, 9, 1, 4, 9, 0, 7, 6, 1, 4, 9, 1, 0,\n",
       "       9, 1, 4, 9, 6, 3, 4, 6, 2, 3, 7, 3, 4, 0, 9, 2, 0, 7, 8, 9, 5, 7,\n",
       "       0, 8, 3, 1, 4, 1, 3, 6, 9, 5, 4, 5, 8, 5, 6, 3, 8, 0, 9, 4, 0, 8,\n",
       "       3, 4, 3, 2, 2, 3, 1, 7, 5, 6, 4, 5, 4, 3, 9, 2, 7, 6, 9, 2, 9, 7,\n",
       "       1, 6, 2, 7, 1, 0, 0, 5, 3, 4, 4, 4, 9, 1, 4, 5, 7, 7, 0, 8, 8, 8,\n",
       "       0, 2, 9, 0, 4, 4, 1, 8, 4, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the test results\n",
    "y_pred = linear_svm.predict(test_X)\n",
    "print(\"============\")\n",
    "print(\"y prediction\")\n",
    "print(\"============\")\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Confusion Matrix\n",
      "================\n",
      "[[45  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 45  0  0  0  0  0  0  1  0]\n",
      " [ 0  1 43  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 44  0  1  0  0  1  0]\n",
      " [ 0  0  0  0 45  0  0  0  0  0]\n",
      " [ 0  1  0  0  0 45  0  0  0  0]\n",
      " [ 0  1  0  0  0  0 44  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 43  0  2]\n",
      " [ 0  2  1  0  0  0  0  0 40  0]\n",
      " [ 0  0  0  0  0  2  0  0  1 42]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matirx to calculate the performance\n",
    "confusion_matrix_lsvc_performance = confusion_matrix(test_y, y_pred)\n",
    "print(\"================\")\n",
    "print(\"Confusion Matrix\")\n",
    "print(\"================\")\n",
    "print(confusion_matrix_lsvc_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Report\n",
      "======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        45\n",
      "           1       0.90      0.98      0.94        46\n",
      "           2       0.98      0.98      0.98        44\n",
      "           3       1.00      0.96      0.98        46\n",
      "           4       1.00      1.00      1.00        45\n",
      "           5       0.94      0.98      0.96        46\n",
      "           6       1.00      0.98      0.99        45\n",
      "           7       1.00      0.96      0.98        45\n",
      "           8       0.93      0.93      0.93        43\n",
      "           9       0.95      0.93      0.94        45\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       450\n",
      "   macro avg       0.97      0.97      0.97       450\n",
      "weighted avg       0.97      0.97      0.97       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report\n",
    "report = classification_report(test_y, y_pred)\n",
    "print(\"======\")\n",
    "print(\"Report\")\n",
    "print(\"======\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================\n",
      "Accuracy for Linear SVM Model\n",
      "=============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9688888888888889"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy\n",
    "# Calculating accuracy using the sklearn_matrix\n",
    "print(\"=============================\")\n",
    "print(\"Accuracy for Linear SVM Model\")\n",
    "print(\"=============================\")\n",
    "accuracy_score(test_y, y_pred,normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================\n",
      "Weighted_Precision for Linear SVM Model\n",
      "=======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9699545454545454"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"=======================================\")\n",
    "print(\"Weighted_Precision for Linear SVM Model\")\n",
    "print(\"=======================================\")\n",
    "precision_score(test_y,y_pred,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "Weighted_Recall for Linear SVM Model\n",
      "====================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9688888888888889"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"====================================\")\n",
    "print(\"Weighted_Recall for Linear SVM Model\")\n",
    "print(\"====================================\")\n",
    "recall_score(test_y,y_pred,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9688888888888889"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy Manually\n",
    "Accuracy=(confusion_matrix_lsvc_performance[0][0]+confusion_matrix_lsvc_performance[1][1]\n",
    "+confusion_matrix_lsvc_performance[2][2]+confusion_matrix_lsvc_performance[3][3]\n",
    "+confusion_matrix_lsvc_performance[4][4]+confusion_matrix_lsvc_performance[5][5]\n",
    "+confusion_matrix_lsvc_performance[6][6]+confusion_matrix_lsvc_performance[7][7]\n",
    "+confusion_matrix_lsvc_performance[8][8]+confusion_matrix_lsvc_performance[9][9])/450\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3. Gaussian Kernal SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernal_rbf = SVC(kernel='rbf',gamma=\"auto\")\n",
    "kernal_rbf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============\n",
      "y prediction\n",
      "============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5, 5, 0, 1, 5, 8, 5, 5, 6, 6, 6, 9, 5, 5, 5, 5, 0, 5, 5, 5, 8, 5,\n",
       "       5, 2, 1, 5, 5, 5, 7, 5, 5, 5, 5, 2, 5, 2, 2, 5, 5, 9, 0, 2, 3, 5,\n",
       "       5, 5, 5, 0, 5, 5, 5, 5, 5, 3, 3, 5, 7, 0, 5, 6, 5, 5, 5, 5, 5, 1,\n",
       "       5, 1, 5, 1, 7, 7, 7, 5, 5, 5, 5, 5, 9, 5, 5, 7, 4, 5, 5, 5, 5, 1,\n",
       "       5, 6, 5, 0, 9, 4, 6, 9, 3, 5, 3, 9, 5, 5, 5, 5, 5, 6, 1, 5, 2, 5,\n",
       "       6, 5, 5, 9, 2, 5, 2, 5, 5, 3, 5, 9, 9, 5, 5, 5, 5, 5, 5, 4, 5, 3,\n",
       "       5, 7, 1, 3, 4, 5, 3, 5, 5, 6, 3, 6, 1, 5, 6, 7, 5, 3, 5, 5, 5, 5,\n",
       "       5, 5, 0, 0, 5, 5, 5, 5, 5, 5, 0, 5, 2, 3, 0, 2, 2, 2, 7, 5, 0, 9,\n",
       "       3, 3, 5, 6, 5, 1, 0, 0, 5, 2, 5, 5, 5, 3, 5, 3, 5, 5, 5, 5, 5, 5,\n",
       "       5, 6, 3, 0, 5, 5, 5, 1, 5, 5, 3, 5, 1, 6, 5, 0, 9, 5, 5, 5, 8, 6,\n",
       "       3, 5, 0, 5, 5, 5, 3, 5, 0, 8, 3, 5, 5, 7, 5, 7, 9, 5, 5, 3, 4, 5,\n",
       "       5, 5, 5, 5, 4, 1, 3, 5, 1, 5, 5, 5, 4, 5, 0, 3, 9, 7, 0, 8, 4, 5,\n",
       "       5, 9, 9, 9, 6, 5, 5, 5, 5, 4, 5, 1, 3, 5, 6, 2, 0, 9, 1, 3, 5, 3,\n",
       "       5, 5, 2, 5, 5, 5, 5, 7, 0, 7, 5, 8, 7, 4, 5, 7, 5, 5, 6, 7, 6, 6,\n",
       "       5, 5, 8, 2, 5, 5, 5, 5, 5, 9, 5, 5, 9, 9, 8, 4, 5, 5, 5, 5, 6, 7,\n",
       "       6, 5, 6, 0, 5, 5, 3, 4, 7, 3, 5, 5, 4, 5, 5, 5, 6, 5, 4, 9, 1, 0,\n",
       "       5, 1, 4, 9, 6, 3, 4, 6, 2, 5, 7, 5, 4, 5, 9, 5, 5, 7, 5, 9, 5, 7,\n",
       "       0, 8, 3, 5, 4, 5, 5, 6, 9, 5, 5, 5, 8, 5, 6, 3, 5, 5, 9, 4, 0, 8,\n",
       "       5, 4, 3, 5, 2, 3, 5, 7, 5, 6, 4, 5, 4, 5, 9, 5, 5, 5, 5, 2, 9, 5,\n",
       "       5, 5, 5, 7, 5, 5, 0, 5, 3, 5, 5, 4, 5, 5, 4, 5, 5, 7, 0, 5, 5, 5,\n",
       "       0, 2, 9, 0, 4, 5, 5, 8, 4, 5])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = kernal_rbf.predict(test_X)\n",
    "print(\"============\")\n",
    "print(\"y prediction\")\n",
    "print(\"============\")\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "Calculating the confusion matirx\n",
      "================================\n",
      "[[29  0  0  0  0 16  0  0  0  0]\n",
      " [ 0 18  0  0  0 28  0  0  0  0]\n",
      " [ 0  0 20  0  0 24  0  0  0  0]\n",
      " [ 0  0  0 35  0 11  0  0  0  0]\n",
      " [ 0  0  0  0 26 19  0  0  0  0]\n",
      " [ 0  0  0  0  0 46  0  0  0  0]\n",
      " [ 0  0  0  0  0 16 29  0  0  0]\n",
      " [ 0  0  0  0  0 20  0 25  0  0]\n",
      " [ 0  0  0  0  0 31  0  0 12  0]\n",
      " [ 0  0  0  0  0 16  0  0  0 29]]\n"
     ]
    }
   ],
   "source": [
    "#Calculating the confusion matirx\n",
    "print(\"================================\")\n",
    "print(\"Calculating the confusion matirx\") \n",
    "print(\"================================\")\n",
    "confusion_matix_rbf_performance=confusion_matrix(test_y, y_pred)\n",
    "print(confusion_matix_rbf_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Report\n",
      "======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.64      0.78        45\n",
      "           1       1.00      0.39      0.56        46\n",
      "           2       1.00      0.45      0.62        44\n",
      "           3       1.00      0.76      0.86        46\n",
      "           4       1.00      0.58      0.73        45\n",
      "           5       0.20      1.00      0.34        46\n",
      "           6       1.00      0.64      0.78        45\n",
      "           7       1.00      0.56      0.71        45\n",
      "           8       1.00      0.28      0.44        43\n",
      "           9       1.00      0.64      0.78        45\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       450\n",
      "   macro avg       0.92      0.60      0.66       450\n",
      "weighted avg       0.92      0.60      0.66       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Report\n",
    "print(\"======\")\n",
    "print(\"Report\")\n",
    "print(\"======\")\n",
    "report = classification_report(test_y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "Accuracy for Gaussian Kernel\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5977777777777777"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy\n",
    "# Calculating accuracy using the sklearn_matrix\n",
    "print(\"============================\")\n",
    "print(\"Accuracy for Gaussian Kernel\")\n",
    "print(\"============================\")\n",
    "accuracy_score(test_y, y_pred,normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================\n",
      "Weighted_Precision for Gaussian Kernel\n",
      "======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9184924131179638"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weighted Precision for Gaussian Kernel\n",
    "print(\"======================================\")\n",
    "print(\"Weighted_Precision for Gaussian Kernel\")\n",
    "print(\"======================================\")\n",
    "precision_score(test_y,y_pred,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "Weighted_Recall for Gaussian Kernel\n",
      "===================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5977777777777777"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weighted Recall for Gaussian Kernel\n",
    "print(\"===================================\")\n",
    "print(\"Weighted_Recall for Gaussian Kernel\")\n",
    "print(\"===================================\")\n",
    "recall_score(test_y,y_pred,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5977777777777777"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy Manually\n",
    "Accuracy=(confusion_matix_rbf_performance[0][0]+confusion_matix_rbf_performance[1][1]\n",
    "+confusion_matix_rbf_performance[2][2]+confusion_matix_rbf_performance[3][3]\n",
    "+confusion_matix_rbf_performance[4][4]+confusion_matix_rbf_performance[5][5]\n",
    "+confusion_matix_rbf_performance[6][6]+confusion_matix_rbf_performance[7][7]\n",
    "+confusion_matix_rbf_performance[8][8]+confusion_matix_rbf_performance[9][9])/450\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 4. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============\n",
      "y prediction\n",
      "============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 9, 0, 1, 7, 8, 7, 7, 6, 6, 6, 9, 8, 5, 5, 7, 0, 1, 8, 9, 8, 8,\n",
       "       8, 2, 1, 7, 4, 4, 7, 8, 1, 5, 1, 2, 7, 2, 2, 7, 5, 9, 0, 2, 3, 5,\n",
       "       7, 7, 4, 0, 2, 2, 0, 2, 5, 3, 3, 5, 7, 0, 1, 6, 7, 4, 2, 8, 0, 1,\n",
       "       8, 1, 2, 1, 7, 7, 7, 2, 8, 1, 6, 4, 9, 6, 5, 7, 4, 6, 5, 5, 8, 1,\n",
       "       8, 6, 5, 0, 9, 4, 6, 4, 3, 8, 3, 9, 2, 7, 1, 5, 7, 6, 1, 8, 2, 8,\n",
       "       6, 8, 0, 9, 2, 1, 2, 1, 0, 8, 5, 9, 9, 8, 1, 9, 5, 1, 5, 4, 0, 3,\n",
       "       5, 7, 1, 3, 4, 8, 5, 6, 0, 6, 3, 6, 7, 4, 6, 7, 8, 3, 8, 5, 7, 7,\n",
       "       0, 8, 0, 0, 8, 5, 1, 5, 5, 8, 0, 5, 8, 3, 0, 2, 2, 2, 7, 4, 0, 9,\n",
       "       3, 3, 9, 6, 7, 1, 0, 0, 6, 2, 5, 8, 5, 3, 7, 3, 8, 8, 5, 6, 4, 5,\n",
       "       5, 6, 3, 0, 5, 8, 5, 1, 0, 4, 3, 7, 8, 6, 2, 0, 9, 1, 7, 6, 8, 6,\n",
       "       3, 0, 0, 5, 6, 5, 3, 5, 0, 8, 3, 3, 7, 7, 9, 7, 9, 8, 2, 3, 4, 8,\n",
       "       1, 2, 8, 5, 4, 7, 3, 5, 1, 7, 5, 7, 4, 6, 0, 8, 9, 7, 0, 8, 4, 8,\n",
       "       9, 9, 9, 9, 6, 1, 0, 5, 5, 4, 0, 1, 2, 8, 6, 2, 0, 9, 1, 3, 7, 3,\n",
       "       7, 0, 2, 6, 6, 6, 8, 7, 0, 7, 8, 8, 7, 4, 8, 7, 1, 1, 6, 7, 6, 6,\n",
       "       8, 4, 3, 2, 9, 7, 5, 7, 6, 9, 8, 8, 9, 9, 8, 4, 7, 2, 5, 2, 6, 7,\n",
       "       6, 8, 6, 0, 6, 4, 3, 4, 7, 3, 9, 8, 4, 9, 0, 7, 6, 1, 4, 9, 7, 0,\n",
       "       8, 8, 4, 7, 6, 3, 4, 6, 2, 3, 7, 3, 7, 0, 9, 2, 0, 7, 8, 7, 5, 7,\n",
       "       0, 8, 3, 8, 4, 1, 7, 6, 9, 5, 7, 5, 8, 5, 6, 3, 8, 0, 9, 7, 0, 8,\n",
       "       3, 4, 3, 2, 2, 3, 1, 7, 7, 6, 4, 5, 4, 3, 9, 2, 7, 6, 9, 8, 5, 7,\n",
       "       1, 6, 1, 7, 6, 0, 0, 5, 3, 7, 4, 4, 9, 1, 4, 5, 7, 7, 0, 1, 8, 8,\n",
       "       0, 2, 9, 0, 7, 4, 1, 8, 4, 6])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = nb.predict(test_X)\n",
    "print(\"============\")\n",
    "print(\"y prediction\")\n",
    "print(\"============\")\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "Calculating the confusion matirx\n",
      "================================\n",
      "[[45  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 28  0  0  0  0  2  6  9  1]\n",
      " [ 0  3 33  0  0  0  0  0  8  0]\n",
      " [ 0  0  1 37  0  2  0  2  4  0]\n",
      " [ 0  0  0  0 35  0  0 10  0  0]\n",
      " [ 0  0  0  0  0 42  0  2  2  0]\n",
      " [ 0  0  0  0  0  0 45  0  0  0]\n",
      " [ 0  0  0  0  1  1  0 42  0  1]\n",
      " [ 0  5  0  1  0  0  0  3 34  0]\n",
      " [ 1  1  0  0  1  2  0  2  4 34]]\n"
     ]
    }
   ],
   "source": [
    "#Calculating the confusion matirx\n",
    "print(\"================================\")\n",
    "print(\"Calculating the confusion matirx\") \n",
    "print(\"================================\")\n",
    "confusion_matix_nb_performance=confusion_matrix(test_y, y_pred)\n",
    "print(confusion_matix_nb_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Report\n",
      "======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        45\n",
      "           1       0.76      0.61      0.67        46\n",
      "           2       0.97      0.75      0.85        44\n",
      "           3       0.97      0.80      0.88        46\n",
      "           4       0.95      0.78      0.85        45\n",
      "           5       0.89      0.91      0.90        46\n",
      "           6       0.96      1.00      0.98        45\n",
      "           7       0.63      0.93      0.75        45\n",
      "           8       0.56      0.79      0.65        43\n",
      "           9       0.94      0.76      0.84        45\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       450\n",
      "   macro avg       0.86      0.83      0.84       450\n",
      "weighted avg       0.86      0.83      0.84       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Report\n",
    "print(\"======\")\n",
    "print(\"Report\")\n",
    "print(\"======\")\n",
    "report = classification_report(test_y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "Accuracy for Naive Bayes\n",
      "========================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy\n",
    "# Calculating accuracy using the sklearn_matrix\n",
    "print(\"========================\")\n",
    "print(\"Accuracy for Naive Bayes\")\n",
    "print(\"========================\")\n",
    "accuracy_score(test_y, y_pred,normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "Weighted_Precision for Naive Bayes\n",
      "===================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8616958472140037"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weighted Precision for Naive Bayes\n",
    "print(\"===================================\")\n",
    "print(\"Weighted_Precision for Naive Bayes\")\n",
    "print(\"===================================\")\n",
    "precision_score(test_y,y_pred,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Weighted_Recall for Naive Bayes\n",
      "===============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weighted Recall for Naive Bayes\n",
    "print(\"===============================\")\n",
    "print(\"Weighted_Recall for Naive Bayes\")\n",
    "print(\"===============================\")\n",
    "recall_score(test_y,y_pred,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy Manually\n",
    "Accuracy=(confusion_matix_nb_performance[0][0]+confusion_matix_nb_performance[1][1]\n",
    "+confusion_matix_nb_performance[2][2]+confusion_matix_nb_performance[3][3]\n",
    "+confusion_matix_nb_performance[4][4]+confusion_matix_nb_performance[5][5]\n",
    "+confusion_matix_nb_performance[6][6]+confusion_matix_nb_performance[7][7]\n",
    "+confusion_matix_nb_performance[8][8]+confusion_matix_nb_performance[9][9])/450\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 5. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_dt = DecisionTreeClassifier()\n",
    "clf_dt.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============\n",
      "y prediction\n",
      "============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 9, 0, 1, 7, 8, 7, 7, 6, 6, 6, 9, 8, 5, 5, 8, 0, 1, 8, 7, 8, 1,\n",
       "       8, 2, 1, 7, 6, 4, 7, 3, 4, 5, 8, 2, 3, 2, 2, 4, 5, 9, 0, 2, 3, 5,\n",
       "       4, 7, 8, 0, 2, 4, 0, 2, 5, 9, 3, 5, 7, 0, 8, 6, 3, 4, 3, 8, 0, 1,\n",
       "       2, 1, 2, 1, 7, 7, 7, 2, 2, 2, 6, 6, 9, 1, 5, 7, 4, 6, 5, 5, 8, 8,\n",
       "       8, 6, 5, 0, 9, 4, 6, 9, 1, 6, 3, 9, 2, 7, 6, 8, 5, 6, 1, 8, 2, 8,\n",
       "       6, 2, 0, 9, 2, 2, 2, 1, 0, 3, 5, 9, 9, 8, 1, 9, 8, 1, 5, 4, 1, 3,\n",
       "       5, 7, 1, 3, 4, 2, 9, 6, 0, 6, 3, 6, 1, 4, 6, 7, 2, 3, 8, 4, 9, 7,\n",
       "       0, 8, 0, 0, 8, 5, 8, 5, 8, 8, 0, 5, 2, 3, 0, 2, 2, 2, 7, 4, 0, 9,\n",
       "       3, 3, 9, 6, 1, 1, 0, 0, 4, 2, 5, 8, 5, 7, 8, 8, 1, 3, 1, 6, 4, 5,\n",
       "       8, 6, 3, 0, 5, 8, 5, 1, 0, 4, 3, 7, 1, 6, 2, 0, 9, 1, 1, 4, 8, 6,\n",
       "       3, 0, 0, 5, 6, 5, 3, 5, 0, 8, 3, 3, 1, 7, 4, 7, 9, 8, 2, 3, 4, 1,\n",
       "       1, 2, 8, 4, 4, 2, 3, 5, 1, 7, 5, 7, 4, 6, 0, 9, 9, 7, 0, 8, 4, 8,\n",
       "       9, 9, 9, 9, 6, 1, 0, 5, 5, 4, 0, 1, 3, 3, 6, 2, 0, 9, 1, 3, 7, 3,\n",
       "       7, 0, 2, 6, 3, 4, 2, 7, 0, 7, 8, 8, 7, 4, 4, 7, 8, 9, 6, 7, 6, 6,\n",
       "       9, 4, 8, 2, 9, 4, 5, 6, 2, 8, 2, 8, 9, 9, 8, 4, 1, 2, 5, 4, 6, 7,\n",
       "       6, 8, 6, 0, 6, 4, 3, 4, 7, 3, 4, 1, 6, 9, 8, 7, 6, 6, 4, 9, 8, 0,\n",
       "       7, 2, 4, 9, 6, 3, 4, 6, 2, 1, 7, 3, 4, 0, 9, 2, 0, 7, 8, 9, 5, 7,\n",
       "       0, 8, 3, 1, 4, 1, 3, 6, 9, 5, 4, 5, 8, 5, 6, 1, 8, 0, 9, 4, 0, 8,\n",
       "       3, 4, 3, 8, 2, 3, 1, 7, 5, 6, 4, 5, 4, 9, 9, 2, 7, 6, 9, 2, 9, 7,\n",
       "       3, 6, 2, 7, 1, 0, 0, 5, 3, 4, 4, 4, 9, 1, 4, 5, 7, 7, 0, 2, 1, 8,\n",
       "       0, 2, 9, 0, 4, 4, 1, 8, 4, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = clf_dt.predict(test_X)\n",
    "print(\"============\")\n",
    "print(\"y prediction\")\n",
    "print(\"============\")\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "Calculating the confusion matirx\n",
      "================================\n",
      "[[43  1  0  0  0  0  0  0  1  0]\n",
      " [ 0 36  2  1  1  0  2  0  3  1]\n",
      " [ 0  0 38  1  2  0  1  0  2  0]\n",
      " [ 0  3  0 35  0  1  0  1  2  4]\n",
      " [ 0  0  0  0 40  0  4  1  0  0]\n",
      " [ 0  0  0  0  3 39  0  0  4  0]\n",
      " [ 0  1  1  1  3  0 39  0  0  0]\n",
      " [ 0  2  0  1  0  0  0 41  1  0]\n",
      " [ 0  0  3  1  0  0  0  0 38  1]\n",
      " [ 1  0  1  1  2  0  0  1  2 37]]\n"
     ]
    }
   ],
   "source": [
    "#Calculating the confusion matirx\n",
    "print(\"================================\")\n",
    "print(\"Calculating the confusion matirx\") \n",
    "print(\"================================\")\n",
    "confusion_matix_dt_performance=confusion_matrix(test_y, y_pred)\n",
    "print(confusion_matix_dt_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Report\n",
      "======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97        45\n",
      "           1       0.84      0.78      0.81        46\n",
      "           2       0.84      0.86      0.85        44\n",
      "           3       0.85      0.76      0.80        46\n",
      "           4       0.78      0.89      0.83        45\n",
      "           5       0.97      0.85      0.91        46\n",
      "           6       0.85      0.87      0.86        45\n",
      "           7       0.93      0.91      0.92        45\n",
      "           8       0.72      0.88      0.79        43\n",
      "           9       0.86      0.82      0.84        45\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       450\n",
      "   macro avg       0.86      0.86      0.86       450\n",
      "weighted avg       0.86      0.86      0.86       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Report\n",
    "print(\"======\")\n",
    "print(\"Report\")\n",
    "print(\"======\")\n",
    "report = classification_report(test_y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "Accuracy for Decision Tree\n",
      "==========================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8577777777777778"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy\n",
    "# Calculating accuracy using the sklearn_matrix\n",
    "print(\"==========================\")\n",
    "print(\"Accuracy for Decision Tree\")\n",
    "print(\"==========================\")\n",
    "accuracy_score(test_y, y_pred,normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "Weighted_Precision for Decision Tree\n",
      "====================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8637599500587907"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weighted Precision for Decision Tree\n",
    "print(\"====================================\")\n",
    "print(\"Weighted_Precision for Decision Tree\")\n",
    "print(\"====================================\")\n",
    "precision_score(test_y,y_pred,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "Weighted_Recall for Decision Tree\n",
      "=================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8577777777777778"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weighted Recall for Decision Tree\n",
    "print(\"=================================\")\n",
    "print(\"Weighted_Recall for Decision Tree\")\n",
    "print(\"=================================\")\n",
    "recall_score(test_y,y_pred,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8577777777777778"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy Manually\n",
    "Accuracy=(confusion_matix_dt_performance[0][0]+confusion_matix_dt_performance[1][1]\n",
    "+confusion_matix_dt_performance[2][2]+confusion_matix_dt_performance[3][3]\n",
    "+confusion_matix_dt_performance[4][4]+confusion_matix_dt_performance[5][5]\n",
    "+confusion_matix_dt_performance[6][6]+confusion_matix_dt_performance[7][7]\n",
    "+confusion_matix_dt_performance[8][8]+confusion_matix_dt_performance[9][9])/450\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 6. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 300)\n",
    "# Fit the model to the training set\n",
    "rf.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============\n",
      "y prediction\n",
      "============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 1, 0, 1, 7, 8, 7, 7, 6, 6, 6, 9, 5, 5, 5, 7, 0, 1, 8, 7, 8, 1,\n",
       "       1, 2, 1, 7, 4, 4, 7, 3, 1, 5, 2, 2, 8, 2, 2, 4, 5, 9, 0, 2, 3, 5,\n",
       "       4, 7, 7, 0, 2, 2, 0, 2, 5, 3, 3, 5, 7, 0, 1, 6, 7, 4, 2, 8, 0, 1,\n",
       "       2, 1, 2, 1, 7, 7, 7, 2, 2, 2, 6, 4, 9, 1, 5, 7, 4, 6, 5, 5, 8, 1,\n",
       "       8, 6, 5, 0, 9, 4, 6, 9, 3, 2, 3, 9, 2, 7, 1, 5, 5, 6, 1, 8, 2, 8,\n",
       "       6, 9, 0, 9, 2, 8, 2, 1, 9, 3, 5, 9, 9, 8, 1, 9, 5, 1, 5, 4, 0, 3,\n",
       "       5, 7, 1, 3, 4, 2, 9, 6, 0, 6, 3, 6, 1, 4, 6, 7, 8, 3, 8, 5, 8, 7,\n",
       "       0, 8, 0, 0, 8, 5, 1, 5, 5, 8, 0, 5, 2, 3, 0, 2, 2, 2, 7, 4, 0, 9,\n",
       "       3, 3, 9, 6, 1, 1, 0, 0, 6, 2, 5, 8, 5, 3, 8, 3, 1, 8, 7, 6, 4, 5,\n",
       "       5, 6, 3, 0, 5, 8, 5, 1, 0, 4, 3, 7, 1, 6, 2, 0, 9, 1, 7, 6, 8, 6,\n",
       "       3, 0, 0, 5, 6, 5, 3, 5, 0, 8, 3, 3, 1, 7, 9, 7, 9, 8, 2, 3, 4, 1,\n",
       "       1, 2, 8, 4, 4, 1, 3, 5, 1, 4, 5, 7, 4, 6, 0, 3, 9, 7, 0, 8, 4, 8,\n",
       "       9, 9, 9, 9, 6, 1, 0, 5, 5, 4, 0, 1, 3, 3, 6, 2, 0, 9, 1, 3, 7, 3,\n",
       "       7, 0, 2, 6, 6, 6, 2, 7, 0, 7, 8, 8, 7, 4, 5, 7, 8, 9, 6, 7, 6, 6,\n",
       "       9, 4, 8, 2, 9, 4, 5, 4, 6, 9, 1, 8, 9, 9, 8, 4, 1, 2, 5, 2, 6, 7,\n",
       "       6, 8, 6, 0, 6, 4, 3, 4, 7, 3, 3, 1, 4, 9, 0, 7, 6, 1, 4, 9, 1, 0,\n",
       "       9, 1, 4, 9, 6, 3, 4, 6, 2, 3, 7, 3, 4, 0, 9, 2, 0, 7, 8, 9, 5, 7,\n",
       "       0, 8, 3, 1, 4, 1, 3, 6, 9, 5, 4, 5, 8, 5, 6, 3, 8, 0, 9, 4, 0, 8,\n",
       "       3, 4, 3, 2, 2, 3, 1, 7, 5, 6, 4, 5, 4, 9, 9, 2, 7, 6, 9, 2, 9, 7,\n",
       "       1, 6, 2, 7, 6, 0, 0, 5, 3, 4, 4, 4, 9, 1, 4, 5, 7, 7, 0, 1, 1, 8,\n",
       "       0, 2, 9, 0, 4, 4, 1, 8, 4, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = rf.predict(test_X)\n",
    "print(\"============\")\n",
    "print(\"y prediction\")\n",
    "print(\"============\")\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "Calculating the confusion matirx\n",
      "================================\n",
      "[[45  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 46  0  0  0  0  0  0  0  0]\n",
      " [ 0  1 43  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  1  0  1  0  2]\n",
      " [ 0  0  0  0 45  0  0  0  0  0]\n",
      " [ 0  0  0  0  1 45  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 45  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 45  0  0]\n",
      " [ 0  3  0  0  0  0  0  0 40  0]\n",
      " [ 0  0  0  1  0  1  0  0  1 42]]\n"
     ]
    }
   ],
   "source": [
    "#Calculating the confusion matirx\n",
    "print(\"================================\")\n",
    "print(\"Calculating the confusion matirx\") \n",
    "print(\"================================\")\n",
    "confusion_matix_rf_performance=confusion_matrix(test_y, y_pred)\n",
    "print(confusion_matix_rf_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Report\n",
      "======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        45\n",
      "           1       0.92      1.00      0.96        46\n",
      "           2       1.00      0.98      0.99        44\n",
      "           3       0.98      0.91      0.94        46\n",
      "           4       0.98      1.00      0.99        45\n",
      "           5       0.96      0.98      0.97        46\n",
      "           6       1.00      1.00      1.00        45\n",
      "           7       0.98      1.00      0.99        45\n",
      "           8       0.98      0.93      0.95        43\n",
      "           9       0.95      0.93      0.94        45\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       450\n",
      "   macro avg       0.97      0.97      0.97       450\n",
      "weighted avg       0.97      0.97      0.97       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Report\n",
    "print(\"======\")\n",
    "print(\"Report\")\n",
    "print(\"======\")\n",
    "report = classification_report(test_y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "Accuracy for Random Forest\n",
      "==========================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy\n",
    "# Calculating accuracy using the sklearn_matrix\n",
    "print(\"==========================\")\n",
    "print(\"Accuracy for Random Forest\")\n",
    "print(\"==========================\")\n",
    "accuracy_score(test_y, y_pred,normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "Weighted_Precision for Random Forest\n",
      "====================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9738711755049755"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weighted Precision for Random Forest\n",
    "print(\"====================================\")\n",
    "print(\"Weighted_Precision for Random Forest\")\n",
    "print(\"====================================\")\n",
    "precision_score(test_y,y_pred,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "Weighted_Recall for Random Forest\n",
      "====================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weighted Recall for Random Forest\n",
    "print(\"====================================\")\n",
    "print(\"Weighted_Recall for Random Forest\")\n",
    "print(\"====================================\")\n",
    "recall_score(test_y,y_pred,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy Manually\n",
    "Accuracy=(confusion_matix_rf_performance[0][0]+confusion_matix_rf_performance[1][1]\n",
    "+confusion_matix_rf_performance[2][2]+confusion_matix_rf_performance[3][3]\n",
    "+confusion_matix_rf_performance[4][4]+confusion_matix_rf_performance[5][5]\n",
    "+confusion_matix_rf_performance[6][6]+confusion_matix_rf_performance[7][7]\n",
    "+confusion_matix_rf_performance[8][8]+confusion_matix_rf_performance[9][9])/450\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Method 7. Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('Random Forest', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "       ...r', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))],\n",
       "         flatten_transform=None, n_jobs=None, voting='hard', weights=None)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "# Instantiate individual classifiers\n",
    "SEED = 1\n",
    "rf = RandomForestClassifier(n_estimators = 300)\n",
    "knn = KNeighborsClassifier(n_neighbors = 3, p = 2)\n",
    "dt = DecisionTreeClassifier(random_state = SEED)\n",
    "nb = GaussianNB()\n",
    "kernal_rbf = SVC(kernel='rbf',gamma=\"auto\")\n",
    "#kernal_poly = SVC(kernel='poly',degree=3)\n",
    "linear_svm = SVC(kernel='linear')\n",
    "#Define a list called classifier that contains the tuples (classifier_name, classifier)\n",
    "classifiers = [('Random Forest',rf),\n",
    "               ('K Nearest Neighbours',knn),\n",
    "               ('Classification Tree',dt),\n",
    "               ('Naive',nb),\n",
    "               ('RBF',kernal_rbf),\n",
    "               ('SVM',linear_svm)]\n",
    "\n",
    "#Instantiate a VotingClassifier 'vc'\n",
    "vc = VotingClassifier(estimators=classifiers)\n",
    "#Fit 'vc' to the train set\n",
    "vc.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============\n",
      "y prediction\n",
      "============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 1, 0, 1, 7, 8, 7, 7, 6, 6, 6, 9, 5, 5, 5, 7, 0, 1, 8, 7, 8, 1,\n",
       "       1, 2, 1, 7, 4, 4, 7, 3, 1, 5, 2, 2, 8, 2, 2, 4, 5, 9, 0, 2, 3, 5,\n",
       "       4, 7, 5, 0, 2, 2, 0, 2, 5, 3, 3, 5, 7, 0, 1, 6, 7, 4, 2, 8, 0, 1,\n",
       "       2, 1, 2, 1, 7, 7, 7, 2, 2, 2, 6, 4, 9, 1, 5, 7, 4, 6, 5, 5, 8, 1,\n",
       "       8, 6, 5, 0, 9, 4, 6, 9, 3, 2, 3, 9, 2, 7, 1, 5, 5, 6, 1, 8, 2, 8,\n",
       "       6, 9, 0, 9, 2, 8, 2, 1, 9, 3, 5, 9, 9, 8, 1, 9, 5, 1, 5, 4, 0, 3,\n",
       "       5, 7, 1, 3, 4, 2, 3, 6, 0, 6, 3, 6, 1, 4, 6, 7, 8, 3, 8, 5, 8, 7,\n",
       "       0, 8, 0, 0, 8, 5, 1, 5, 5, 8, 0, 5, 2, 3, 0, 2, 2, 2, 7, 4, 0, 9,\n",
       "       3, 3, 9, 6, 1, 1, 0, 0, 6, 2, 5, 8, 5, 3, 8, 3, 1, 3, 7, 6, 4, 5,\n",
       "       5, 6, 3, 0, 5, 8, 5, 1, 0, 4, 3, 7, 1, 6, 2, 0, 9, 1, 7, 6, 8, 6,\n",
       "       3, 0, 0, 5, 6, 5, 3, 5, 0, 8, 3, 3, 1, 7, 9, 7, 9, 8, 2, 3, 4, 1,\n",
       "       1, 2, 8, 5, 4, 1, 3, 5, 1, 4, 5, 7, 4, 6, 0, 3, 9, 7, 0, 8, 4, 8,\n",
       "       9, 9, 9, 9, 6, 1, 0, 5, 5, 4, 0, 1, 3, 3, 6, 2, 0, 9, 1, 3, 7, 3,\n",
       "       7, 0, 2, 6, 6, 6, 2, 7, 0, 7, 8, 8, 7, 4, 5, 7, 8, 9, 6, 7, 6, 6,\n",
       "       9, 4, 8, 2, 9, 4, 5, 4, 6, 9, 2, 8, 9, 9, 8, 4, 1, 2, 5, 2, 6, 7,\n",
       "       6, 8, 6, 0, 6, 4, 3, 4, 7, 3, 9, 1, 4, 9, 0, 7, 6, 1, 4, 9, 1, 0,\n",
       "       9, 1, 4, 9, 6, 3, 4, 6, 2, 3, 7, 3, 4, 0, 9, 2, 0, 7, 8, 9, 5, 7,\n",
       "       0, 8, 3, 1, 4, 1, 3, 6, 9, 5, 4, 5, 8, 5, 6, 3, 8, 0, 9, 4, 0, 8,\n",
       "       3, 4, 3, 2, 2, 3, 1, 7, 5, 6, 4, 5, 4, 3, 9, 2, 7, 6, 9, 2, 9, 7,\n",
       "       1, 6, 2, 7, 6, 0, 0, 5, 3, 4, 4, 4, 9, 1, 4, 5, 7, 7, 0, 1, 1, 8,\n",
       "       0, 2, 9, 0, 4, 4, 1, 8, 4, 1])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict test set labels\n",
    "y_pred = vc.predict(test_X)\n",
    "print(\"============\")\n",
    "print(\"y prediction\")\n",
    "print(\"============\")\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "Calculating the confusion matirx\n",
      "================================\n",
      "[[45  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 46  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 44  0  1  0  1  0  0]\n",
      " [ 0  0  0  0 45  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 46  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 45  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 44  0  0]\n",
      " [ 0  3  0  0  0  0  0  0 40  0]\n",
      " [ 0  0  0  1  0  1  0  0  0 43]]\n"
     ]
    }
   ],
   "source": [
    "#Calculating the confusion matirx\n",
    "print(\"================================\")\n",
    "print(\"Calculating the confusion matirx\") \n",
    "print(\"================================\")\n",
    "confusion_matix_vc_performance=confusion_matrix(test_y, y_pred)\n",
    "print(confusion_matix_vc_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Report\n",
      "======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        45\n",
      "           1       0.94      1.00      0.97        46\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       0.98      0.96      0.97        46\n",
      "           4       1.00      1.00      1.00        45\n",
      "           5       0.94      1.00      0.97        46\n",
      "           6       1.00      1.00      1.00        45\n",
      "           7       0.98      0.98      0.98        45\n",
      "           8       1.00      0.93      0.96        43\n",
      "           9       1.00      0.96      0.98        45\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       450\n",
      "   macro avg       0.98      0.98      0.98       450\n",
      "weighted avg       0.98      0.98      0.98       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Report\n",
    "print(\"======\")\n",
    "print(\"Report\")\n",
    "print(\"======\")\n",
    "report = classification_report(test_y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Accuracy for Voting Classifier\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9822222222222222"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy\n",
    "# Calculating accuracy using the sklearn_matrix\n",
    "print(\"==============================\")\n",
    "print(\"Accuracy for Voting Classifier\")\n",
    "print(\"==============================\")\n",
    "accuracy_score(test_y, y_pred,normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Weighted_Precision for Voting Classifier\n",
      "========================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9829891660367851"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"========================================\")\n",
    "print(\"Weighted_Precision for Voting Classifier\")\n",
    "print(\"========================================\")\n",
    "precision_score(test_y,y_pred,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================\n",
      "Weighted_Recall for Voting Classifier\n",
      "=====================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9822222222222222"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"=====================================\")\n",
    "print(\"Weighted_Recall for Voting Classifier\")\n",
    "print(\"=====================================\")\n",
    "recall_score(test_y,y_pred,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9822222222222222"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy Manually\n",
    "Accuracy=(confusion_matix_vc_performance[0][0]+confusion_matix_vc_performance[1][1]\n",
    "+confusion_matix_vc_performance[2][2]+confusion_matix_vc_performance[3][3]\n",
    "+confusion_matix_vc_performance[4][4]+confusion_matix_vc_performance[5][5]\n",
    "+confusion_matix_vc_performance[6][6]+confusion_matix_vc_performance[7][7]\n",
    "+confusion_matix_vc_performance[8][8]+confusion_matix_vc_performance[9][9])/450\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Method 8. Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "# Instantiate a classifier KNN\n",
    "knn = KNeighborsClassifier(n_neighbors = 3, p = 2)\n",
    "# Instantiate a BaggingClassifier 'bc'\n",
    "bc = BaggingClassifier(base_estimator=knn, n_estimators = 100, n_jobs=-1)\n",
    "#Fit 'bc' to the train set\n",
    "bc.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============\n",
      "y prediction\n",
      "============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 1, 0, 1, 7, 8, 7, 7, 6, 6, 6, 9, 5, 5, 5, 7, 0, 1, 8, 7, 8, 1,\n",
       "       1, 2, 1, 7, 4, 4, 7, 3, 1, 5, 2, 2, 8, 2, 2, 4, 5, 9, 0, 2, 3, 5,\n",
       "       4, 7, 7, 0, 2, 2, 0, 2, 5, 3, 3, 5, 7, 0, 1, 6, 7, 4, 2, 8, 0, 1,\n",
       "       2, 1, 2, 1, 7, 7, 7, 2, 2, 2, 6, 4, 9, 1, 5, 7, 4, 6, 5, 5, 8, 1,\n",
       "       8, 6, 3, 0, 9, 4, 6, 9, 3, 2, 3, 9, 2, 7, 1, 5, 5, 6, 1, 8, 2, 8,\n",
       "       6, 9, 0, 9, 2, 8, 2, 1, 9, 3, 5, 9, 9, 8, 1, 9, 5, 1, 5, 4, 0, 3,\n",
       "       5, 7, 1, 3, 4, 2, 3, 6, 0, 6, 3, 6, 1, 4, 6, 7, 8, 3, 1, 5, 8, 7,\n",
       "       0, 8, 0, 0, 8, 5, 1, 5, 5, 8, 0, 5, 2, 3, 0, 2, 2, 2, 7, 4, 0, 9,\n",
       "       3, 3, 9, 6, 1, 1, 0, 0, 6, 2, 5, 8, 5, 3, 8, 3, 1, 3, 7, 6, 4, 5,\n",
       "       5, 6, 3, 0, 5, 8, 5, 1, 0, 4, 3, 7, 1, 6, 2, 0, 9, 1, 7, 6, 8, 6,\n",
       "       3, 0, 0, 5, 6, 5, 3, 5, 0, 8, 3, 3, 1, 7, 9, 7, 9, 8, 2, 3, 4, 1,\n",
       "       1, 2, 8, 5, 4, 1, 3, 5, 1, 4, 5, 7, 4, 6, 0, 3, 9, 7, 0, 8, 4, 8,\n",
       "       9, 9, 9, 9, 6, 1, 0, 5, 5, 4, 0, 1, 3, 3, 6, 2, 0, 9, 1, 3, 7, 3,\n",
       "       7, 0, 2, 6, 6, 6, 2, 7, 0, 7, 8, 8, 7, 4, 5, 7, 8, 9, 6, 7, 6, 6,\n",
       "       9, 4, 8, 2, 9, 4, 5, 4, 6, 9, 2, 8, 9, 9, 8, 4, 1, 2, 5, 2, 6, 7,\n",
       "       6, 8, 6, 0, 6, 4, 3, 4, 7, 3, 3, 1, 4, 9, 0, 7, 6, 1, 4, 9, 1, 0,\n",
       "       9, 1, 4, 9, 6, 3, 4, 6, 2, 3, 7, 3, 4, 0, 9, 2, 0, 7, 8, 9, 5, 7,\n",
       "       0, 8, 3, 1, 4, 1, 7, 6, 9, 5, 4, 5, 8, 5, 6, 3, 8, 0, 9, 4, 0, 8,\n",
       "       3, 4, 3, 2, 2, 3, 1, 7, 5, 6, 4, 5, 4, 3, 9, 2, 7, 6, 9, 2, 9, 7,\n",
       "       1, 6, 2, 7, 6, 0, 0, 5, 3, 4, 4, 4, 9, 1, 4, 5, 7, 7, 0, 1, 1, 8,\n",
       "       0, 2, 9, 0, 4, 4, 1, 8, 4, 1])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict test set labels\n",
    "y_pred = bc.predict(test_X)\n",
    "print(\"============\")\n",
    "print(\"y prediction\")\n",
    "print(\"============\")\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "Calculating the confusion matirx\n",
      "================================\n",
      "[[45  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 46  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 44  0  0  0  2  0  0]\n",
      " [ 0  0  0  0 45  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 46  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 45  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 45  0  0]\n",
      " [ 0  4  0  0  0  0  0  0 39  0]\n",
      " [ 0  0  0  2  0  1  0  0  0 42]]\n"
     ]
    }
   ],
   "source": [
    "#Calculating the confusion matirx\n",
    "print(\"================================\")\n",
    "print(\"Calculating the confusion matirx\") \n",
    "print(\"================================\")\n",
    "confusion_matix_bagging_performance=confusion_matrix(test_y, y_pred)\n",
    "print(confusion_matix_bagging_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Report\n",
      "======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        45\n",
      "           1       0.92      1.00      0.96        46\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       0.96      0.96      0.96        46\n",
      "           4       1.00      1.00      1.00        45\n",
      "           5       0.98      1.00      0.99        46\n",
      "           6       1.00      1.00      1.00        45\n",
      "           7       0.96      1.00      0.98        45\n",
      "           8       1.00      0.91      0.95        43\n",
      "           9       1.00      0.93      0.97        45\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       450\n",
      "   macro avg       0.98      0.98      0.98       450\n",
      "weighted avg       0.98      0.98      0.98       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Report\n",
    "print(\"======\")\n",
    "print(\"Report\")\n",
    "print(\"======\")\n",
    "report = classification_report(test_y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "Accuracy for Bagging Model\n",
      "==========================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy\n",
    "# Calculating accuracy using the sklearn_matrix\n",
    "print(\"==========================\")\n",
    "print(\"Accuracy for Bagging Model\")\n",
    "print(\"==========================\")\n",
    "accuracy_score(test_y, y_pred,normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "Weighted_Precision for Bagging Model\n",
      "====================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9809475177304964"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"====================================\")\n",
    "print(\"Weighted_Precision for Bagging Model\")\n",
    "print(\"====================================\")\n",
    "precision_score(test_y,y_pred,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "Weighted_Recall for Bagging Model\n",
      "=================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"=================================\")\n",
    "print(\"Weighted_Recall for Bagging Model\")\n",
    "print(\"=================================\")\n",
    "recall_score(test_y,y_pred,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy Manually\n",
    "Accuracy=(confusion_matix_bagging_performance[0][0]+confusion_matix_bagging_performance[1][1]\n",
    "+confusion_matix_bagging_performance[2][2]+confusion_matix_bagging_performance[3][3]\n",
    "+confusion_matix_bagging_performance[4][4]+confusion_matix_bagging_performance[5][5]\n",
    "+confusion_matix_bagging_performance[6][6]+confusion_matix_bagging_performance[7][7]\n",
    "+confusion_matix_bagging_performance[8][8]+confusion_matix_bagging_performance[9][9])/450\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 3: Accuracy Results Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th></th>\n",
    "            <th>KNN</th>\n",
    "            <th>L_SVM</th>\n",
    "            <th>RBF_SVM</th>\n",
    "            <th>NB</th>\n",
    "            <th>DT</th>\n",
    "            <th>RF</th>\n",
    "            <th>Voting</th>\n",
    "            <th>Bagging</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Accuracy</td>\n",
    "            <td>0.9800</td>\n",
    "            <td>0.9688</td>\n",
    "            <td>0.5977</td>\n",
    "            <td>0.8333</td>\n",
    "            <td>0.8577</td>\n",
    "            <td>0.9733</td>\n",
    "            <td>0.9822</td>\n",
    "            <td>0.9800</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Weighted Precision</td>\n",
    "            <td>0.9809</td>\n",
    "            <td>0.9699</td>\n",
    "            <td>0.9184</td>\n",
    "            <td>0.8616</td>\n",
    "            <td>0.8637</td>\n",
    "            <td>0.9738</td>\n",
    "            <td>0.9829</td>\n",
    "            <td>0.9809</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Weighted Recall</td>\n",
    "            <td>0.9800</td>\n",
    "            <td>0.9688</td>\n",
    "            <td>0.5977</td>\n",
    "            <td>0.8333</td>\n",
    "            <td>0.8577</td>\n",
    "            <td>0.9733</td>\n",
    "            <td>0.9822</td>\n",
    "            <td>0.9800</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model selection to train the data set is based on the accuracy.Therefore,from the table above the best models to train the dataset are the KNN, Voting Classifier and the Bagging. And also observersed that the accuracy and the Weighted Recall values are same for all the models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
